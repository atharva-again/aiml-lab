{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e733eb8",
   "metadata": {},
   "source": [
    "# Linear Regression Analysis on Advertising Dataset\n",
    "\n",
    "This notebook demonstrates a complete linear regression workflow using scikit-learn:\n",
    "- **Data Preparation**: Load and explore the advertising dataset\n",
    "- **Train-Test Split**: Divide data into 80% training and 20% testing sets\n",
    "- **Model Training**: Train a linear regression model using Ordinary Least Squares\n",
    "- **Evaluation**: Assess performance using MSE and R² metrics\n",
    "- **Interpretation**: Analyze feature coefficients and their impact on sales\n",
    "\n",
    "## Dataset Overview\n",
    "The advertising dataset contains advertising spending (TV, Radio, Newspaper) in thousands of dollars and the resulting sales in thousands of units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb5e800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Configure matplotlib for better visualization\n",
    "plt.style.use('default')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310bd6e7",
   "metadata": {},
   "source": [
    "## Step 1: Data Preparation\n",
    "\n",
    "Load the advertising dataset and identify features and target variable. We'll examine the data structure and basic statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f963486a",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/advertising.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-2205096737.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load the advertising dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/advertising.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Display first few rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"First few rows of the dataset:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/advertising.csv'"
     ]
    }
   ],
   "source": [
    "# Load the advertising dataset\n",
    "df = pd.read_csv('advertising.csv')\n",
    "\n",
    "# Display first few rows\n",
    "print(\"First few rows of the dataset:\")\n",
    "print(df.head())\n",
    "print(f\"\\nDataset shape: {df.shape}\")\n",
    "print(f\"Number of samples: {df.shape[0]}, Number of features: {df.shape[1] - 1}\")\n",
    "\n",
    "# Display basic statistics\n",
    "print(\"\\nBasic statistics:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b4ba5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify features (X) and target (y)\n",
    "X = df[['TV', 'Radio', 'Newspaper']]  # Features\n",
    "y = df['Sales']  # Target variable\n",
    "\n",
    "print(\"Features (X):\")\n",
    "print(X.head())\n",
    "print(f\"\\nTarget (y):\")\n",
    "print(y.head())\n",
    "print(f\"\\nFeatures shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a8a00f",
   "metadata": {},
   "source": [
    "## Step 2: Train-Test Split\n",
    "\n",
    "Split the data into training (80%) and testing (20%) sets. We use a fixed random state for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a29a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]} samples ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"Testing set size: {X_test.shape[0]} samples ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"\\nTraining features shape: {X_train.shape}\")\n",
    "print(f\"Testing features shape: {X_test.shape}\")\n",
    "print(f\"Training target shape: {y_train.shape}\")\n",
    "print(f\"Testing target shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5c58a8",
   "metadata": {},
   "source": [
    "## Step 3: Model Training\n",
    "\n",
    "Train a Linear Regression model using the training data. The `.fit()` method uses Ordinary Least Squares (OLS) to calculate optimal coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba57fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and train the Linear Regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Model training completed!\")\n",
    "print(f\"Model parameters: {model.get_params()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f04fa12",
   "metadata": {},
   "source": [
    "## Step 4: Model Evaluation\n",
    "\n",
    "Generate predictions on the test set and evaluate the model using Mean Squared Error (MSE) and R² score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd06dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Model Evaluation Metrics:\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "print(f\"R² Score: {r2:.4f}\")\n",
    "print(f\"\\nInterpretation: The model explains {r2*100:.2f}% of the variance in Sales.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c18c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predicted vs actual values\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Scatter plot: Actual vs Predicted\n",
    "axes[0].scatter(y_test, y_pred, alpha=0.6, s=50)\n",
    "axes[0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "axes[0].set_xlabel('Actual Sales', fontsize=12)\n",
    "axes[0].set_ylabel('Predicted Sales', fontsize=12)\n",
    "axes[0].set_title('Predicted vs Actual Sales', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Residuals plot\n",
    "residuals = y_test - y_pred\n",
    "axes[1].scatter(y_pred, residuals, alpha=0.6, s=50)\n",
    "axes[1].axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "axes[1].set_xlabel('Predicted Sales', fontsize=12)\n",
    "axes[1].set_ylabel('Residuals', fontsize=12)\n",
    "axes[1].set_title('Residuals Plot', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473a66d8",
   "metadata": {},
   "source": [
    "## Step 5: Coefficient Interpretation\n",
    "\n",
    "Extract and interpret the model's intercept and coefficients to understand how each advertising channel impacts sales predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5106c926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract intercept and coefficients\n",
    "intercept = model.intercept_\n",
    "coefficients = model.coef_\n",
    "feature_names = X.columns\n",
    "\n",
    "print(\"Linear Regression Equation:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Sales = {intercept:.4f}\", end=\"\")\n",
    "for name, coef in zip(feature_names, coefficients):\n",
    "    sign = \"+\" if coef >= 0 else \"-\"\n",
    "    print(f\" {sign} {abs(coef):.4f} × {name}\", end=\"\")\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "print(\"\\nCoefficient Interpretation:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"Intercept (Base Sales): {intercept:.4f} (in thousands of units)\")\n",
    "print(\"\\nFeature Coefficients:\")\n",
    "for name, coef in zip(feature_names, coefficients):\n",
    "    print(f\"  {name:12s}: {coef:8.4f} (impact per $1000 spent)\")\n",
    "    interpretation = \"positive\" if coef > 0 else \"negative\"\n",
    "    print(f\"               → {interpretation.capitalize()} relationship with sales\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0193836d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize coefficient importance\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "colors = ['green' if coef > 0 else 'red' for coef in coefficients]\n",
    "bars = ax.barh(feature_names, coefficients, color=colors, alpha=0.7)\n",
    "\n",
    "ax.set_xlabel('Coefficient Value', fontsize=12)\n",
    "ax.set_title('Feature Coefficients - Impact on Sales', fontsize=14, fontweight='bold')\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (name, coef) in enumerate(zip(feature_names, coefficients)):\n",
    "    ax.text(coef, i, f' {coef:.4f}', va='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey Insights:\")\n",
    "print(\"-\" * 60)\n",
    "sorted_features = sorted(zip(feature_names, coefficients), key=lambda x: abs(x[1]), reverse=True)\n",
    "for i, (name, coef) in enumerate(sorted_features, 1):\n",
    "    print(f\"{i}. {name}: Coefficient = {coef:.4f}\")\n",
    "    print(f\"   For every additional $1000 spent on {name}, sales increase by {coef:.4f} units.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c59296",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrates a complete linear regression workflow:\n",
    "\n",
    "1. **Data Preparation**: Loaded the advertising dataset with 200 samples and 3 features (TV, Radio, Newspaper advertising spend)\n",
    "2. **Train-Test Split**: Split data 80/20 for proper model evaluation\n",
    "3. **Model Training**: Used scikit-learn's LinearRegression with Ordinary Least Squares optimization\n",
    "4. **Evaluation**: Assessed model performance using MSE and R² metrics\n",
    "5. **Interpretation**: Analyzed how each advertising channel impacts sales predictions\n",
    "\n",
    "The model's coefficients show the marginal impact of each advertising channel, helping stakeholders understand which channels provide the best return on investment.\n",
    "\n",
    "**Next Steps:**\n",
    "- Consider feature scaling for better coefficient comparison\n",
    "- Explore polynomial features for non-linear relationships\n",
    "- Apply cross-validation for more robust performance estimates\n",
    "- Test other regression models (Ridge, Lasso) to compare performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
